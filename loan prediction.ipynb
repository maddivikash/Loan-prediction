{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as py\n",
    "import seaborn as sns\n",
    "train_data = pd.read_csv('../input/loan-dataset/train_x.csv')\n",
    "train_data.info()\n",
    "train_label_data=pd.read_csv('../input/loan-dataset/train_y.csv')\n",
    "train_label_data.info()\n",
    "train_data = train_data.merge(train_label_data,on = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.06875,
     "end_time": "2020-12-07T06:52:49.776395",
     "exception": false,
     "start_time": "2020-12-07T06:52:49.707645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.0649,
     "end_time": "2020-12-07T06:52:49.870912",
     "exception": false,
     "start_time": "2020-12-07T06:52:49.806012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "new_train_data = train_data[train_data.Label.notnull()]  \n",
    "new_train_data.head(7)\n",
    "\n",
    "length = len(train_data.ID)\n",
    "length_new = len(new_train_data.ID)\n",
    "per = (1 - length_new/length) *100\n",
    "print(\"Percent of data dropped is \",per)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.259818,
     "end_time": "2020-12-07T06:52:50.160902",
     "exception": false,
     "start_time": "2020-12-07T06:52:49.901084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(x = \"Label\",data = new_train_data)\n",
    "\n",
    "l = len(new_train_data.Label)\n",
    "s = new_train_data.Label.sum()\n",
    "print(s)\n",
    "percent = (s/l)*100\n",
    "print(\"Percentage of labels which are default is\",percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_columns=['Loan type', 'Occupation type','Age' ]\n",
    "for col in interested_columns:\n",
    "    categorical_bin = pd.crosstab(new_train_data[col],new_train_data['Label'])\n",
    "    categorical_bin.div(categorical_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\n",
    "    py.xlabel(f'{col}')\n",
    "    P = py.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = new_train_data.corr(method = 'pearson')\n",
    "f, ax = py.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(10, 275, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, cmap=cmap, square=True,\n",
    "            linewidths=0.5, cbar_kws={\"shrink\": 0.5}, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.256455,
     "end_time": "2020-12-07T06:52:51.449319",
     "exception": false,
     "start_time": "2020-12-07T06:52:50.192864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_columns= ['Expense','Income', 'Score1','Score2','Score3','Score4', 'Score5']\n",
    "\n",
    "\n",
    "fig,axes = py.subplots(3,3,figsize=(20,14))\n",
    "for idx,cat_col in enumerate(numerical_columns):\n",
    "     row,col = idx//3,idx%3\n",
    "     sns.boxplot(y=cat_col,data=train_data,x='Label',ax=axes[row,col])\n",
    "\n",
    "print(train_data[numerical_columns].describe())\n",
    "py.subplots_adjust(hspace=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interested_columns = ['Expense','Income', 'Score1','Score2','Score3','Score4','Score5','Label']\n",
    "sns.pairplot(new_train_data[interested_columns][:5000],hue='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.054276,
     "end_time": "2020-12-07T06:52:51.537357",
     "exception": false,
     "start_time": "2020-12-07T06:52:51.483081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "categorical_columns=['ID','Loan type', 'Occupation type','Age' ]\n",
    "numerical_columns= ['ID','Expense','Income', 'Score1','Score2','Score3','Score4', 'Score5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_train_data.drop(columns='Label')\n",
    "y = new_train_data['Label']\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp= SimpleImputer(strategy = 'most_frequent')\n",
    "X_categorical = imp.fit_transform(X[categorical_columns])\n",
    "X_categorical = pd.DataFrame(X_categorical,columns=categorical_columns)\n",
    "\n",
    "imp= SimpleImputer(strategy = 'mean')\n",
    "X_numerical = imp.fit_transform(X[numerical_columns])\n",
    "X_numerical = pd.DataFrame(X_numerical,columns=numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.133974,
     "end_time": "2020-12-07T06:52:52.995509",
     "exception": false,
     "start_time": "2020-12-07T06:52:52.861535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X_numerical.merge(X_categorical,on=\"ID\")\n",
    "X = X.drop(columns = 'ID')\n",
    "\n",
    "X = pd.get_dummies(X,drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.089798,
     "end_time": "2020-12-07T06:52:53.119457",
     "exception": false,
     "start_time": "2020-12-07T06:52:53.029659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smk = SMOTE(random_state=0)\n",
    "X_new,y_new = smk.fit_sample(X,y)\n",
    "len(y_new)\n",
    "\n",
    "l = len(y_new)\n",
    "s = y_new.sum()\n",
    "print(s)\n",
    "percent = (s/l)*100\n",
    "print(\"Percentage of labels which are default after balancing the data set is\",percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interested_columns = ['Expense','Income', 'Score1','Score2','Score3','Score4','Score5','Label']\n",
    "smote_df = pd.concat([X_new, y_new], axis=1)\n",
    "smote_df = smote_df.sample(frac=1).reset_index(drop=True)\n",
    "sns.pairplot(smote_df[interested_columns][:5000],hue='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns= ['Expense','Income', 'Score1','Score2','Score3','Score4', 'Score5']\n",
    "categorical_columns =['Loan type_B','Occupation type_Y','Occupation type_Z','Age_1.0']\n",
    "\n",
    "X_standard =pd.DataFrame([])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_standard[numerical_columns] =pd.DataFrame(StandardScaler().fit_transform(X_new[numerical_columns]))\n",
    "\n",
    "\n",
    "X_standard[categorical_columns]=X_new[categorical_columns]\n",
    "X_standard.info()\n",
    "X_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_encoded,X_test_encoded,y_train,y_test = train_test_split(X_standard,y_new,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 20.254615,
     "end_time": "2020-12-07T06:53:14.229885",
     "exception": false,
     "start_time": "2020-12-07T06:52:53.97527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "train_accuracies = []\n",
    "train_f1_scores = []\n",
    "test_accuracies = []\n",
    "test_f1_scores = []\n",
    "thresholds = []\n",
    "\n",
    "\n",
    "for thresh in np.arange(0.1,0.9,0.1): \n",
    "    logreg_clf = LogisticRegression(solver='liblinear')\n",
    "    logreg_clf.fit(X_train_encoded,y_train)\n",
    "    \n",
    "    y_pred_train_thresh = logreg_clf.predict_proba(X_train_encoded)[:,1]\n",
    "    y_pred_train = (y_pred_train_thresh > thresh).astype(int)\n",
    "\n",
    "    train_acc = accuracy_score(y_train,y_pred_train)\n",
    "    train_f1 = f1_score(y_train,y_pred_train)\n",
    "    \n",
    "    y_pred_test_thresh = logreg_clf.predict_proba(X_test_encoded)[:,1]\n",
    "    y_pred_test = (y_pred_test_thresh > thresh).astype(int) \n",
    "    \n",
    "    test_acc = accuracy_score(y_test,y_pred_test)\n",
    "    test_f1 = f1_score(y_test,y_pred_test)\n",
    "    \n",
    "    train_accuracies.append(train_acc)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_f1_scores.append(test_f1)\n",
    "    thresholds.append(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.423175,
     "end_time": "2020-12-07T06:53:14.689847",
     "exception": false,
     "start_time": "2020-12-07T06:53:14.266672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Threshold_logreg = {\"Training Accuracy\": train_accuracies, \"Test Accuracy\": test_accuracies, \"Training F1\": train_f1_scores, \"Test F1\":test_f1_scores, \"Decision Threshold\": thresholds }\n",
    "Threshold_logreg_df = pd.DataFrame.from_dict(Threshold_logreg)\n",
    "\n",
    "plot_df = Threshold_logreg_df.melt('Decision Threshold',var_name='Metrics',value_name=\"Values\")\n",
    "fig,ax = py.subplots(figsize=(15,5))\n",
    "sns.pointplot(x=\"Decision Threshold\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.541904,
     "end_time": "2020-12-07T06:53:17.270472",
     "exception": false,
     "start_time": "2020-12-07T06:53:14.728568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "logreg_clf = LogisticRegression(solver='liblinear')\n",
    "logreg_clf.fit(X_train_encoded,y_train)\n",
    "    \n",
    "y_pred_train_thresh = logreg_clf.predict_proba(X_train_encoded)[:,1]\n",
    "y_pred_train = (y_pred_train_thresh > 0.45).astype(int)\n",
    "\n",
    "train_acc = accuracy_score(y_train,y_pred_train)\n",
    "train_f1 = f1_score(y_train,y_pred_train)\n",
    "    \n",
    "y_pred_test_thresh = logreg_clf.predict_proba(X_test_encoded)[:,1]\n",
    "y_pred_test = (y_pred_test_thresh >0.45).astype(int) \n",
    "    \n",
    "test_acc = accuracy_score(y_test,y_pred_test)\n",
    "test_f1 = f1_score(y_test,y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.16599,
     "end_time": "2020-12-07T06:53:17.47774",
     "exception": false,
     "start_time": "2020-12-07T06:53:17.31175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Training acc. is :\", train_acc)\n",
    "print(\"Training f1 :\",train_f1)\n",
    "pd.crosstab(y_train, y_pred_train, rownames=['Actual'], colnames=['Predicted'], margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.110815,
     "end_time": "2020-12-07T06:53:17.633627",
     "exception": false,
     "start_time": "2020-12-07T06:53:17.522812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Test acc. is :\", test_acc)\n",
    "print(\"Test f1 :\",test_f1)\n",
    "pd.crosstab(y_test, y_pred_test, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "ax=py.gca()\n",
    "rfc=plot_roc_curve(logreg_clf,X_test_encoded,y_test,ax=ax,alpha=0.8)\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_matrix = logreg_clf.coef_\n",
    "print(coeff_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_encoded,X_test_encoded,y_train,y_test = train_test_split(X_new,y_new,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 15.408422,
     "end_time": "2020-12-07T06:53:33.167239",
     "exception": false,
     "start_time": "2020-12-07T06:53:17.758817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train_encoded,y_train)\n",
    "y_pred = tree_clf.predict(X_train_encoded)\n",
    "print(\"Training Data Set Accuracy: \", accuracy_score(y_train,y_pred))\n",
    "print(\"Training Data F1 Score \", f1_score(y_train,y_pred))\n",
    "\n",
    "print(\"Validation Mean F1 Score: \",cross_val_score(tree_clf,X_train_encoded,y_train,cv=5,scoring='f1_macro').mean())\n",
    "print(\"Validation Mean Accuracy: \",cross_val_score(tree_clf,X_train_encoded,y_train,cv=5,scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.087731,
     "end_time": "2020-12-07T06:53:33.297396",
     "exception": false,
     "start_time": "2020-12-07T06:53:33.209665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = tree_clf.predict(X_test_encoded)\n",
    "print(\"Test Data Set Accuracy: \", accuracy_score(y_test,y_pred))\n",
    "print(\"Test Data F1 Score \", f1_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 220.906248,
     "end_time": "2020-12-07T06:57:14.246384",
     "exception": false,
     "start_time": "2020-12-07T06:53:33.340136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "training_accuracy = []\n",
    "val_accuracy = []\n",
    "training_f1 = []\n",
    "val_f1 = []\n",
    "tree_depths = []\n",
    "test_accuracy = []\n",
    "test_val_accuracy =[]\n",
    "test_val_f1 = []\n",
    "test_f1 =[]\n",
    "\n",
    "for depth in range(1,20):\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    tree_clf.fit(X_train_encoded,y_train)\n",
    "    y_training_pred = tree_clf.predict(X_train_encoded)\n",
    "\n",
    "    training_acc = accuracy_score(y_train,y_training_pred)\n",
    "    train_f1 = f1_score(y_train,y_training_pred)\n",
    "    val_mean_f1 = cross_val_score(tree_clf,X_train_encoded,y_train,cv=5,scoring='f1_macro').mean()\n",
    "    val_mean_accuracy = cross_val_score(tree_clf,X_train_encoded,y_train,cv=5,scoring='accuracy').mean()\n",
    "    \n",
    "    y_test_pred_1 = tree_clf.predict(X_test_encoded)\n",
    "\n",
    "    training_acc_1 = accuracy_score(y_test,y_test_pred_1)\n",
    "    train_f1_1 = f1_score(y_test,y_test_pred_1)\n",
    "    val_mean_f1_1 = cross_val_score(tree_clf,X_test_encoded,y_test,cv=5,scoring='f1_macro').mean()\n",
    "    val_mean_accuracy_1 = cross_val_score(tree_clf,X_test_encoded,y_test,cv=5,scoring='accuracy').mean()\n",
    "    \n",
    "    training_accuracy.append(training_acc)\n",
    "    val_accuracy.append(val_mean_accuracy)\n",
    "    training_f1.append(train_f1)\n",
    "    val_f1.append(val_mean_f1)\n",
    "    tree_depths.append(depth)\n",
    "    \n",
    "     \n",
    "    test_accuracy.append(training_acc_1)\n",
    "    test_val_accuracy.append(val_mean_accuracy_1)\n",
    "    test_f1.append(train_f1_1)\n",
    "    test_val_f1.append(val_mean_f1_1)\n",
    "    \n",
    "\n",
    "Tuning_Max_depth = {\"Training Accuracy\": training_accuracy, \"Validation Accuracy\": val_accuracy, \"Training F1\": training_f1, \"Validation F1\":val_f1, \"Max_Depth\": tree_depths ,\"Test_val_f1\":test_val_f1 , \"Test_val_acc\":test_val_accuracy , \"Test_acc\":test_accuracy , \"Test_f1\":test_f1 }\n",
    "Tuning_Max_depth_df = pd.DataFrame.from_dict(Tuning_Max_depth)\n",
    "\n",
    "plot_df = Tuning_Max_depth_df.melt('Max_Depth',var_name='Metrics',value_name=\"Values\")\n",
    "fig,ax = py.subplots(figsize=(15,5))\n",
    "sns.pointplot(x=\"Max_Depth\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.601634,
     "end_time": "2020-12-07T06:57:14.894226",
     "exception": false,
     "start_time": "2020-12-07T06:57:14.292592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Tuning_Max_depth = {\"Training Accuracy\": training_accuracy, \"Validation Accuracy\": val_accuracy, \"Training F1\": training_f1, \"Validation F1\":val_f1, \"Max_Depth\": tree_depths }\n",
    "Tuning_Max_depth_df = pd.DataFrame.from_dict(Tuning_Max_depth)\n",
    "\n",
    "plot_df = Tuning_Max_depth_df.melt('Max_Depth',var_name='Metrics',value_name=\"Values\")\n",
    "fig,ax = py.subplots(figsize=(15,5))\n",
    "sns.pointplot(x=\"Max_Depth\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.671008,
     "end_time": "2020-12-07T06:57:15.612659",
     "exception": false,
     "start_time": "2020-12-07T06:57:14.941651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Tuning_Max_depth = {  \"Max_Depth\": tree_depths , \"Test_acc\":test_accuracy ,\"Test_val_acc\":test_val_accuracy,\"Test_f1\":test_f1 ,\"Test_val_f1\":test_val_f1  }\n",
    "Tuning_Max_depth_df = pd.DataFrame.from_dict(Tuning_Max_depth)\n",
    "\n",
    "plot_df = Tuning_Max_depth_df.melt('Max_Depth',var_name='Metrics',value_name=\"Values\")\n",
    "fig,ax = py.subplots(figsize=(15,5))\n",
    "sns.pointplot(x=\"Max_Depth\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 9.405541,
     "end_time": "2020-12-07T06:57:25.068553",
     "exception": false,
     "start_time": "2020-12-07T06:57:15.663012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth =8)\n",
    "tree_clf.fit(X_train_encoded,y_train)\n",
    "y_pred = tree_clf.predict(X_train_encoded)\n",
    "print(\"Training Data Set Accuracy: \", accuracy_score(y_train,y_pred))\n",
    "print(\"Training Data F1 Score \", f1_score(y_train,y_pred))\n",
    "\n",
    "print(\"Validation Mean F1 Score: \",cross_val_score(tree_clf,X_train_encoded,y_train,cv=5,scoring='f1_macro').mean())\n",
    "print(\"Validation Mean Accuracy: \",cross_val_score(tree_clf,X_train_encoded,y_train,cv=5,scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.153149,
     "end_time": "2020-12-07T06:57:25.277822",
     "exception": false,
     "start_time": "2020-12-07T06:57:25.124673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.crosstab(y_train, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.905894,
     "end_time": "2020-12-07T06:57:27.235713",
     "exception": false,
     "start_time": "2020-12-07T06:57:25.329819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = tree_clf.predict(X_test_encoded)\n",
    "print(\"Test Data Set Accuracy: \", accuracy_score(y_test,y_pred))\n",
    "print(\"Test Data F1 Score \", f1_score(y_test,y_pred))\n",
    "\n",
    "print(\"Validation Test Mean F1 Score: \",cross_val_score(tree_clf,X_test_encoded,y_test,cv=5,scoring='f1_macro').mean())\n",
    "print(\"Validation Test Mean Accuracy: \",cross_val_score(tree_clf,X_test_encoded,y_test,cv=5,scoring='accuracy').mean())\n",
    "\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "ax=py.gca()\n",
    "rfc=plot_roc_curve(tree_clf,X_test_encoded,y_test,ax=ax,alpha=0.8)\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 31.576134,
     "end_time": "2020-12-07T06:57:59.090663",
     "exception": false,
     "start_time": "2020-12-07T06:57:27.514529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100,max_depth=14,min_samples_leaf = 10, random_state = 42)\n",
    "rf_clf.fit(X_train_encoded,y_train)\n",
    "y_pred = rf_clf.predict(X_train_encoded)\n",
    "print(\"Train F1 Score \", f1_score(y_train,y_pred))\n",
    "print(\"Train Accuracy \", accuracy_score(y_train,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.151667,
     "end_time": "2020-12-07T06:57:59.298538",
     "exception": false,
     "start_time": "2020-12-07T06:57:59.146871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.crosstab(y_train, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.626695,
     "end_time": "2020-12-07T06:58:00.092405",
     "exception": false,
     "start_time": "2020-12-07T06:57:59.46571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = rf_clf.predict(X_test_encoded)\n",
    "print(\"Test Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Test F1 Score: \",f1_score(y_test,y_pred))\n",
    "print(\"Confusion Matrix on Test Data\")\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "ax=py.gca()\n",
    "rfc=plot_roc_curve(rf_clf,X_test_encoded,y_test,ax=ax,alpha=0.8)\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.056814,
     "end_time": "2020-12-07T06:58:00.323884",
     "exception": false,
     "start_time": "2020-12-07T06:58:00.26707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test_evaluation = pd.read_csv('../input/loan-dataset/test_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_evaluation.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_evaluation_new = X_test_evaluation.drop(columns=\"ID_Test\")\n",
    "X_test_evaluation_new= pd.get_dummies(X_test_evaluation_new,drop_first=True)\n",
    "X_test_evaluation_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_evaluation_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_test_evaluation_new = X_test_evaluation_new[['Expense','Income','Score1','Score2','Score3','Score4','Score5','Loan type_B','Occupation type_Y','Occupation type_Z','Age']]\n",
    "\n",
    "X_test_evaluation_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_evaluation_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_y_new =rf_clf.predict(X_test_evaluation_new)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ID_column =pd.DataFrame(X_test_evaluation[\"ID_Test\"])\n",
    "\n",
    "pred_y = ID_column.copy()\n",
    "pred_y[\"Label_Test\"]= pred_y_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_y.to_csv('pred_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.99)\n",
    "\n",
    "pr_comp=pca.fit_transform(X_standard)\n",
    "pr_df= pd.DataFrame([])\n",
    "pr_df = pd.DataFrame(data = pr_comp,columns = ['Principal_Comp_1','Principal_Comp_2','Principal_Comp_3','Principal_Comp_4','Principal_Comp_5','Principal_Comp_6','Principal_comp_7','Principal_comp_8','Principal_comp_9'])  \n",
    "pr_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "principal_components =['Principal_Comp_1','Principal_Comp_2','Principal_Comp_3','Principal_Comp_4','Principal_Comp_5','Principal_Comp_6','Principal_comp_7','Principal_comp_8','Principal_comp_9']\n",
    "principal_information_percent = pd.DataFrame([])\n",
    "principal_information_percent = pd.DataFrame(principal_components)\n",
    "principal_information_percent['percent variation captured'] = pd.DataFrame(data = pca.explained_variance_ratio_)\n",
    "\n",
    "principal_information_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca2 = PCA(0.95)  \n",
    "\n",
    "pr_comp2=pca2.fit_transform(X_standard)\n",
    "pr_df2 = pd.DataFrame([])\n",
    "pr_df2 = pd.DataFrame(data = pr_comp2,columns = ['New Principal_Comp_1','New Principal_Comp_2','New Princi_Comp_3','New Principal_Comp_4','New Principal_Comp_5','New Principal_Comp_6'])  \n",
    "pr_df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "principal_components_2 =['New Principal_Comp_1','New Principal_Comp_2','New Principal_Comp_3','New Principal_Comp_4','New Principal_Comp_5','New Principal_Comp_6']\n",
    "principal_information_percent_2 = pd.DataFrame([])\n",
    "principal_information_percent_2 = pd.DataFrame(principal_components_2)\n",
    "principal_information_percent_2['percent variation captured'] = pd.DataFrame(data = pca2.explained_variance_ratio_)\n",
    "\n",
    "principal_information_percent_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mi = mutual_info_classif(X_standard, y_new,random_state = 42)\n",
    "print(mi)\n",
    "print(\"Mean value of MI = \", np.mean(mi))\n",
    "print(\"Standard deviation of MI is =\", np.std(mi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "tree_model = ExtraTreesClassifier(random_state = 42)\n",
    "tree_model.fit(X_standard, y_new)\n",
    "importance_list = tree_model.feature_importances_\n",
    "print(importance_list)\n",
    "print(\"Mean value of importance = \", np.mean(importance_list))\n",
    "print(\"Standard deviation of importance is =\", np.std(importance_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
